<html>

<head>
    <meta charset="UTF-8">
    <title>aven:: scholar</title>
    <link rel="icon" href="images/logo.png">
    <link rel="apple-touch-icon" sizes="57x57" href="images/apple-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="images/apple-icon-144x144.png" />
    <link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
    <section id="bar">
        <a href="index.html"><img src="images/logo.svg" width=180 class="logo"></a>
        <nav>
            <p style="text-align: center;">"I enjoy coffee, beer, hotpot and extreme sports."</p>
            <ul>
                <li>
                    <a href="professorship.html"><span>a = "professor"</span></a>
                </li>
                <li>
                    <a href="practice.html" ><span>v = "artist"</span></a>
                </li>
                <li>
                    <a href="research.html" class="tab_highlight"><span>e = "scholar"</span></a>
                </li>
                <li>
                    <a href="entrepreneurship.html"><span>n = "entrepreneur"</span></a>
                </li>
                <li id="contact_aven">
                    <a href="about.html"><span>About</span></a>
                </li>
            </ul>
            <p style="text-align: center;">
                for x in [a,v,e,n]:<br><br>
                "Meanwhile, I respect myself as {} in professional capacities".format(x)</p>
        </nav>
    </section>

    <article>
        <section id="researchStatement" class="content">
            <p class="description">
                <img class="center_img" src="images/research01.png" width="800">
                <br>
                <em>* photo credit to Modern Weekly, Notes On Nature.</em>
                <br>
            </P>
            <p class="subtitle">Research Statement</p>
            <p class="description">
                Artists and other professional creative participants should conduct research as in other fields, so to
                enhance and advance their practices. In my personal experiences, written research is guided through
                cumulative stages of critical reflection and/or interpretive analysis of my practices. I intend to
                develop art projects for specific research question(s) that I want to investigate. Led by research
                questions, I dedicate to conduct a combination of praxis and thinking, where writing actively
                contributes to the creative work itself, functioning as an integral part of the overall research. Both
                culminate the research deliver as exhibited artwork and submission of creative research writing that
                best articulates and reflects ideas. In brief, the creative work is the research itself together with a
                written component informing research.
                <br><br>
                <b>Create with Artificial Intelligence</b><br><br>
                My general practice and research interests spread in interactive media, generative art and machine
                vision for arts applications. And recently, I focus on utilizing artificial intelligence/machine
                learning to create art and have been directed by three questions: 
                <br><br>
                1. can Artificial Intelligence be creative?
                <br>
                2. can we design AI to collaborate with and facilitate, enhance human creativity?
                <br>
                3. and how could the Chinese cultural heritage be involved and evolved?
                <br><br>
                <!-- <em>* full research statement can be found <a href="researchStatement.html" target="_blank">here</a>.</em> -->
            </p>
        </section>

        <section id="publication" class="contnent">

             
            <!-- <button class="collapsible subtitle">Publications</button> -->
            <!-- <p class="description hide_content"> -->
            <!-- <p class="description">
                (updated 02/2019)<br><br>
                (WIP). <strong>ZICHI: A Responsive System that Generate Chinese Guqin Music from Real-time Human
                    Input.</strong><br>
                Work-in-Progress Collaborative Work with Intel AI Academy.
                <br><br>
                (arXiv Preprint Paper). <strong>Machine: The New Art Connoisseur.</strong><br>
                arXiv Preprint, Collaborative Work with Staff from Northwestern University and Intel AI Academy
                <br><br>
                (1st Author, Demo Accepted to NeurIPS 2019 Workshop). <strong>ZICHI.</strong><br>
                The Thirty-third Annual Conference on Neural Information Processing Systems (NeurIPS) 2019, Machine
                Learning for Creativity and Design Workshop, Vancouver, Canada.
                <br><br>
                (Submitted, 1st Author). <strong>Integrating Live Coding and Interactive Syllabus to Engage Students in
                    a Media Arts Course.</strong><br>
                Submitted to The Online Journal of New Horizons in Education.
                <br><br>
                (2nd and Corresponding Author, Paper Accepted to TASIES 2019). <strong>ConfessorBot : Can Machine
                    Learning Algorithms Identify, Understand and even Confess with Human Emotion?</strong><br>
                The 5th Art and Science International Exhibition and Symposium, Beijing, China
                <br><br>
                (1st Author, Demo Accepted to ICCV 2019 Workshop). <strong>Walking Through Shanshui.</strong><br>
                The International Conference On Computer Vision (ICCV) 2019, Second Workshop on Computer Vision for
                Fashion, Art and Design, Seoul, Korea.
                <br><br>
                (1st Author, Paper Accepted to ICCV 2019 Workshop). <strong>Walking Through Shanshui: Generating Chinese
                    Shanshui Paintings via Real-time Tracking of Human Position.</strong><br>
                The International Conference On Computer Vision (ICCV) 2019, Second Workshop on Computer Vision for
                Fashion, Art and Design, Seoul, Korea.
                <br><br>
                (1st Author, Paper Accepted to ICDAR 2019). <strong>An Interactive and Generative Approach for Chinese
                    Shanshui Painting Document.</strong><br>
                The 15th International Conference on Document Analysis and Recognition (ICDAR) 2019, Sydney, Australia.
                <br><br>
                (1st Author, Demo Accepted Demo to NeurIPS 2018 Workshop). <strong>ShanshuiDaDA.</strong><br>
                The Thirty-second Annual Conference on Neural Information Processing Systems (NeurIPS) 2018, Machine
                Learning for Creativity and Design Workshop, Montreal, Canada.
                <br><br>
                (1st Author, Paper Accepted to NeurIPS 2018 Workshop). <strong>ShanshuiDaDA: An Interactive, Generative
                    System towards Chinese Shanshui Painting.</strong><br>
                The Thirty-second Annual Conference on Neural Information Processing Systems (NeurIPS) 2018, Machine
                Learning for Creativity and Design Workshop, Montreal, Canada.
            </p> -->
            
            <button class="collapsible subtitle">Journal Article / Conference Papers Published in Proceedings</button>

            <p class="description">
            <strong>Zhou, Le</strong> and Fuqi Xie (2022). Welcome To Heshan: An Installation To Create Immersive And Entertaining Experiences With Local Art Through Interactive Media Technologies. In: The 24th International Conference on Human-Computer Interaction. (peer reviewed; accepted to HCII 2022).
<br><br>
Li, Zixin and <strong>Le Zhou.</strong> (2021). The Museum of Dreams: Exploring a “Dreaming” Visual Experience via Machine Vision and Visual Synthesis. In: Rau PL.P. (eds) Cross-Cultural Design. Applications in Arts, Learning, Well-being, and Social Development. HCII 2021. Lecture Notes in Computer Science, vol 12772. Springer. (peer reviewed; DOI: 10.1007/978-3-030-77077-8_3; published 28-Oct-2019).
<br><br>
<strong>Zhou, Le,</strong> and Jace Hargis (2020). Integrating Live Coding And Interactive Syllabus To Engage Students In An Interactive Media Arts Course. The Online Journal of New Horizons in Education, 2020: 10(2): 106-114 (peer reviewed; DOI: 10.13140/RG.2.2.29465.57440; ISSN: 2146-7374; published 1-Apr-2020).
<br><br>
<strong>Zhou, Le,</strong> Qiufeng Wang, Kaizhu Huang and Cheng-Hung, Lo (2019). An Interactive and Generative Approach for Chinese Shanshui Painting Document. 2019 International Conference on Document Analysis and Recognition (ICDAR), Sydney, Australia, 2019: 819-824 (peer reviewed; DOI: 10.1109/ICDAR.2019.00136; published 25-Sept-2019).
<br><br>
<strong>Zhou, Le.</strong> (2019). Walking Through Shanshui: Generating Chinese Shanshui Paintings via Real-time Tracking of Human Position.  IEEE/CVF International Conference on Computer Vision Workshop (ICCVW), Seoul, Korea (South), 2019: 3185-3188 (peer reviewed; DOI:10.1109/ICCVW.2019.00395; published 28-Oct-2019).
<br><br>
Zameek, Abdullah, and <strong>Aven Le Zhou.</strong> (2019). ConfessorBot: Can Machine Learning Algorithms Identify, Understand and even Confess with Human Emotion? The 5th Art and Science International Exhibition and Symposium, Beijing, China, 2019: 00-00 (peer reviewed; published 04-Nov-2019)
<br><br>
<strong>Zhou, Le,</strong> Qiufeng Wang, Kaizhu Huang and Cheng-Hung, Lo (2018). ShanshuiDaDA: An Interactive, Generative System towards Chinese Shanshui Painting. The Thirty-second Annual Conference on Neural Information Processing Systems. NeurIPS 2018, Machine Learning for Creativity and Design Workshop, Montreal, Canada. (peer reviewed; published 08-Dec-2018)
</p>

<button class="collapsible subtitle">Demo Published at Conferences</button>


<p class="description">

<strong>Zhou, Le.</strong> (2020). Walking Through Shanshui. The Thirty-fourth Annual Conference on Neural Information Processing Systems. NeurIPS 2020, Machine Learning for Creativity and Design Workshop 4.0, Virtual Online.
<br><br>

<strong>Zhou, Le.</strong> (2019). ZICHI. The Thirty-third Annual Conference on Neural Information Processing Systems. NeurIPS 2019, Machine Learning for Creativity and Design Workshop, Vancouver, Canada.
<br><br>

<strong>Zhou, Le.</strong> (2019). Walking Through Shanshui. The International Conference On Computer Vision. ICCV 2019, Second Workshop on Computer Vision for Fashion, Art and Design, Seoul, Korea.
<br><br>

<strong>Zhou, Le.</strong> (2018). ShanshuiDaDA. The Thirty-second Annual Conference on Neural Information Processing Systems. NeurIPS 2018, Machine Learning for Creativity and Design Workshop, Montreal, Canada.

</p>

<button class="collapsible subtitle">E-Print or Pre-Published Articles</button>
<p class="description">

Wu, Yueshen and <strong>Le Zhou.</strong> (2021). The Running Ink (and) Painting: Re-Generate Chinese Painting Experiences with Interactive Liquid Effects. e-Print On Research Gate, 2021.
<br><br>

<strong>Zhou, Le.</strong> (2020). ZICHI: A Responsive System that Generate Chinese Guqin Music from Real-time Human Input. e-Print On Research Gate, 2020.
<br><br>

Zhu, Yucheng, Yanrong Ji, Yueying Zhang, Linxin Xu, <strong>Aven Le Zhou</strong> and Ellick Chan (2019). Machine: The New Art Connoisseur. e-Print on arXiv, 2019. 
<br><br>

<strong>Zhou, Le.</strong> (2020). Therem{ai}n: An AI Enhanced Musical Instrument that Responds, Accompanies and Inspires. e-Print On Research Gate, 2018.
</p>

<button class="collapsible subtitle">Conference/Symposium/Research Presentations</button>

<p class="description">

Li, Zixin and <strong>Le Zhou.</strong> (2021). The Museum of Dreams: Exploring a “Dreaming” Visual Experience via Machine Vision and Visual Synthesis. Presented at: HCI International 2021, Online, 24-July-2021 – 29-July-2021 (invited, conference oral presentation)
<br><br>
<strong>Zhou, Le.</strong> (2020). Chinese New Literati. Presented at: Master Lectures On Live at Shanghai Library, Shanghai, China. 17-Nov-2020.(invited keynote speaker）
<br><br>
<strong>Zhou, Le.</strong> (2019). Create with Artificial Intelligence. Presented at: New Challenges at the Era of AI and 5G. Shanghai Science and Technology EXPO, Shanghai Exhibition Center, Shanghai, China. 24-Aug-2019.(invited keynote and panel discussion）
<br><br>
<strong>Zhou, Le.</strong> (2019). Create with Artificial Intelligence. Presented at: Musical Artificial Intelligence, MTA Musical Festival. Beijing, China. 30-June-2019. (invited keynote and panel discussion）
<br><br>
<strong>Zhou, Le.</strong> (2019). Create with Artificial Intelligence. Presented at: Artificial Intelligence and Arts, the Trends in China Symposium. Shanghai Maker Carnival, Jiangwan Stadium, Shanghai, China. 18-Oct-2019.(invited keynote and panel discussion）
<br><br>
<strong>Zhou, Le.</strong> (2019). A Responsive System that Generates Chinese Guqin Music from Real-time Human Input. Presented at: IRCAM Forum, Shanghai Conservatory of Music, Shanghai, China. 01-Nov-2019.(invited spotlight speaker）
<br><br>
<strong>Zhou, Le.</strong> (2019). Create with Artificial Intelligence. Presented at: School of Innovation and Art, Shanghai Tech University. Shanghai, China. 28-Nov-2019.(invited speaker）
<br><br>
<strong>Zhou, Le.</strong> (2019). An Interactive and Generative Approach for Chinese Shanshui Painting Document. The 15th International Conference on Document Analysis and Recognition (ICDAR) 2019, Sydney, Australia. 25-Sept-2019.(conference poster presentation）
<br><br>
<strong>Zhou, Le.</strong> (2019). Generate Chinese Shanshui Painting from Real-time Tracking of Human Position. The Second Workshop on Computer Vision for Fashion, Art and Design, Seoul, Korea. 02-Nov-2019.(conference poster presentation）
<br><br>
<strong>Zhou, Le.</strong> (2019). Can Machine Learning Algorithms Identify, Understand and even Confess with Human Emotion? The 5th Art and Science International Exhibition and Symposium, Beijing, China. (conference oral presentation）
<br><br>
<strong>Zhou, Le.</strong> (2018). ShanshuiDaDA. Research Seminar at PremiLab, Xi’an-Jiaotong Liverpool University. Suzhou, China. 09-Nov-2018.
<br><br>
<strong>Zhou, Le.</strong> (2018). ShanshuiDaDA: An Interactive, Generative System towards Chinese Shanshui Painting. Machine Learning for Creativity and Design Workshop, NeurIPS 2018, Montreal, Canada.21-Dec-2018. (conference poster presentation)

</p>
<button class="collapsible subtitle">Research or Practice Awards/Prizes</button>


<p class="description">

<strong>Zhou, Le.</strong> (2020). AI Artist Of the Week, elected by the AI for Good Global Summit, ITU and XPRIZE Foundation.
<br><br>
<strong>Zhou, Le.</strong> (2019). Intel Global Network Software Innovator elected by INTEL.
<br><br>
<strong>Zhou, Le.</strong> (2019) ZAOJIU Youth scholar elected by ZAOJIU.
<br><br>
<strong>Zhou, Le.</strong> (2015) Resident Research Fellow at Interactive Media Arts Program at NYU Shanghai.
<br><br>
<strong>Zhou, Le,</strong> Wanyu Li and Wenhe Li (2019-2020). The first prize of Next Idea Competition, host by TENCENT.
<br><br>
<strong>Zhou, Le.</strong> (2019). The first prize of the Intel AI On PC Early Innovation Global Competition host by INTEL.
<br><br>
<strong>Zhou, Le,</strong> Wanyu Li and Yupeng Cao (2019). Winner (among 40 final recipients of the world) of Google PoweredByTF 2.0 Challenge host by GOOGLE.
<br><br>

</p>
            <p class="description">
                <em>* all publication downloadable at <a href="https://www.researchgate.net/profile/Aven_Zhou"
                        target="_blank">ResearchGate</a> or viewable though the (not up-to-date) <a
                        href="https://scholar.google.com/citations?user=9xoJ3zkAAAAJ&hl=en">Google Scholar</a>.</em>
            </P>
        </section>


    </article>


    <section class="notes">
        <p>
            © Copyright 2020. All Rights Reserved. Aven Le ZHOU, M.S. | artMachines.
        </p>
    </section>

    <script src="script.js" type="text/javascript"></script>

</body>

</html>